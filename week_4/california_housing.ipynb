{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "import matplotlib as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features:\n",
      "    MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "Target feature:\n",
      " 0    4.526\n",
      "1    3.585\n",
      "2    3.521\n",
      "3    3.413\n",
      "4    3.422\n",
      "Name: MedHouseVal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "housing_data = fetch_california_housing(as_frame=True)\n",
    "print('Input features:\\n',housing_data.data.head())\n",
    "print('Target feature:\\n',housing_data.target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized input features:\n",
      " [[0.53966842 0.78431373 0.0435123  ... 0.00149943 0.5674814  0.21115538]\n",
      " [0.53802706 0.39215686 0.03822395 ... 0.00114074 0.565356   0.21215139]\n",
      " [0.46602805 1.         0.05275646 ... 0.00169796 0.5642933  0.21015936]\n",
      " ...\n",
      " [0.08276438 0.31372549 0.03090386 ... 0.0013144  0.73219979 0.31175299]\n",
      " [0.09429525 0.33333333 0.03178269 ... 0.0011515  0.73219979 0.30179283]\n",
      " [0.13025338 0.29411765 0.03125246 ... 0.00154886 0.72582359 0.30976096]]\n",
      "Training set size: 16512\n",
      "(16512, 8) (4128, 8)\n",
      "(16512,) (4128,)\n"
     ]
    }
   ],
   "source": [
    "x=housing_data.data\n",
    "y=housing_data.target\n",
    "\n",
    "#Normalize the input features (attributes)\n",
    "\n",
    "scalar=MinMaxScaler()\n",
    "\n",
    "x_norm=scalar.fit_transform(x)\n",
    "\n",
    "print('Normalized input features:\\n',x_norm)\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_norm, y, test_size=0.2, random_state=42)\n",
    "print('Training set size:',xtrain.shape[0])\n",
    "\n",
    "\n",
    "print(xtrain.shape, xtest.shape)\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build your first multi-layer perceptron model (MLP) using Keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(8,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1) #by default, activation is linear\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your model\n",
    "history = model.fit(xtrain, ytrain, epochs=300, validation_split=0.2, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse, acc = model.evaluate(xtest, ytest, verbose=1)\n",
    "print('loss:', loss, mse, mae)\n",
    "print('accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,301)\n",
    "plt.plot(epochs, train_loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1,301)\n",
    "plt.plot(epochs, train_acc, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
